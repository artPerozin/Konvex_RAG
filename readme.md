# IA_KONVEX_BACKEND

Backend em Python para um sistema de busca e resposta baseado em embeddings de documentos, usando **FastAPI**, **FAISS** e **OpenAI GPT**.

---

## ğŸš€ VisÃ£o Geral

Este projeto oferece uma API para:

- Armazenar documentos
- IndexÃ¡-los com FAISS
- Realizar buscas por similaridade com embeddings gerados por modelos de linguagem
- Responder perguntas usando o contexto recuperado via API do OpenAI GPT

---

## âœ¨ Funcionalidades

- ğŸ” IndexaÃ§Ã£o e busca rÃ¡pida por similaridade usando **FAISS**
- ğŸ§  GeraÃ§Ã£o de embeddings com `sentence-transformers`
- ğŸŒ API REST com **FastAPI** para gerenciar documentos e perguntas
- ğŸ¤– IntegraÃ§Ã£o com **OpenAI GPT** para respostas contextuais
- ğŸ” Uso de variÃ¡veis de ambiente para seguranÃ§a e configuraÃ§Ã£o

---

## ğŸ›  Tecnologias Utilizadas

- Python 3.11+
- FastAPI
- FAISS
- sentence-transformers
- OpenAI Python SDK (`openai`)
- python-dotenv
- requests

---

## ğŸ“‹ PrÃ©-requisitos

- Python 3.11 ou superior
- Virtualenv (recomendado)
- Conta e API Key da OpenAI

---

## âš™ï¸ InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/seu-usuario/IA_KONVEX_BACKEND.git
    cd IA_KONVEX_BACKEND
    ```

2. **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv .venv

    # Windows
    .venv\Scripts\activate

    # Linux/macOS
    source .venv/bin/activate
    ```

3. **Instale as dependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```

---

## â–¶ï¸ Como Rodar

Para iniciar o servidor FastAPI localmente:

```bash
uvicorn rag_api:app --reload
```

## ğŸ“š Endpoints Principais

- `GET /documents/` â€” Lista os documentos indexados
- `POST /documents/` â€” Adiciona um novo documento (com embedding automÃ¡tico)
- `POST /ask/` â€” Envia uma pergunta e recebe a resposta gerada baseada nos documentos

---

## ğŸ§© Como Funciona a Busca

1. Os documentos sÃ£o carregados e seus embeddings sÃ£o gerados pelo modelo `sentence-transformers`.
2. Os embeddings sÃ£o indexados com **FAISS** para busca rÃ¡pida.
3. Ao fazer uma pergunta, o sistema gera o embedding da consulta.
4. Busca os documentos mais similares no Ã­ndice FAISS.
5. Monta um prompt com esses documentos e envia para a API **OpenAI GPT** para gerar uma resposta contextualizada.

---

## ğŸ“ Estrutura do Projeto

```
rag_api.py            # Arquivo principal da API FastAPI
DocumentsController.py # Gerencia documentos e busca FAISS
.env                  # VariÃ¡veis de ambiente
requirements.txt      # DependÃªncias Python
README.md             # Este arquivo
```